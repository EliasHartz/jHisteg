This repository contains the Master Thesis (Computer Science) of Elias Hartz.

Software development is an incremental process in which previous versions of a project are used to construct a new iteration. With intuition telling us that it suffices to test what has been modified or newly introduced during each iteration, this thesis proposes to focus automatic test generation on sections of the source code that were changed by the user, with a special emphasis placed on the impact of that change on the program overall. It describes how each modification's impact can be approximated by
combining statically obtained data about syntactical changes with divergences observed in execution traces and introduces the notion of distinguishing between the syntactic and semantic aspect of a change. An implementation by the name of "jHisteg" is provided that computes and combines these information to both produce and rank testing targets.

"jHisteg" was conceived by Elias Hartz from 2014 to 2015 as part of his Master Thesis at the Software Engineering Chair (Prof. Zeller) at Saarland University, 66123 Saarbr√ºcken, Germany. The software has been released here under Apache License 2.0 (see http://www.apache.org/licenses/LICENSE-2.0.html) and shall be used for good (in contrast to evil). Its exact license and attribution instructions are contained inside the NOTICE directories of this repository.
The thesis document itself is also present, here all rights are (naturally) reserved though the author grants you the permission to read, print and spread it in unmodified form as you see fit. Should any content of this repository be used in an academic context, you must cite (= include a reference to) this thesis.

In short, jHisteg extracts and compiles subject versions from a repository and subsequently instruments them to enable execution trace generation during any run. Furthermore, it compares the versions to obtain the syntactic changes introduced by the programmer (in actual language semantics, not "line 7 was changed").
This analysis is combined with the result of comparing the execution traces inside a specialized abstraction to derives testing targets from these datasets.